{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7eb68e-3b93-4725-82d4-50f0aab846ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import timedelta, datetime  # Import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502ffda3-5521-4b3a-bd4c-257dca5902c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/big/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0add317-644b-4301-ad1c-52db010a15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7fbb74-5b12-4086-9df9-b4bacd81f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 CONFIGURATION\n",
    "NUM_PROJECTS = 100\n",
    "WORKSTREAMS_MIN = 50\n",
    "WORKSTREAMS_MAX = 150\n",
    "\n",
    "NUM_PEOPLE = 2000  # labor resources\n",
    "NUM_EQUIP_TYPES = 30\n",
    "NUM_MAT_TYPES = 30\n",
    "\n",
    "NUM_SUPPLIERS = 80\n",
    "NUM_TEAMS = 500\n",
    "\n",
    "TASKS_PER_PROJECT = 3000  # for each of the 100 projects => 300k tasks total\n",
    "COMMISSIONING_PCT = 0.05  # 5% tasks are CommissioningActivity\n",
    "OVERLAP_PCT = 0.30        # ~30% tasks have some overlapping schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a1ca99-a078-46c9-81ef-a00f1ec2c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define 35 skill types for labor\n",
    "LABOR_SKILLS = [\n",
    "    \"CivilEngineer\", \"Electrician\", \"Carpenter\", \"Plumber\", \"HVACTech\", \"SteelWorker\", \n",
    "    \"ConcreteSpecialist\", \"SitePlanner\", \"InsulationWorker\", \"Rigger\", \"Painter\",\n",
    "    \"Mason\", \"IronWorker\", \"WeldingTech\", \"Surveyor\", \"SafetyEngineer\", \"ProjectManager\",\n",
    "    \"StructuralEngineer\", \"GeotechEngineer\", \"NetworkEngineer\", \"SysAdmin\", \"SecurityTech\",\n",
    "    \"CableInstaller\", \"CraneOperator\", \"DataCenterArchitect\", \"InstrumentationTech\",\n",
    "    \"HeatVentEngineer\", \"FireProtectionTech\", \"LandscapeTech\", \"ElectricPanelInstaller\",\n",
    "    \"PowerDistEngineer\", \"CoolingSystemTech\", \"RoboticsTech\", \"ITIntegrationTech\", \"BackupSysEngineer\"\n",
    "]\n",
    "\n",
    "# 30 equipment types\n",
    "EQUIPMENT_TYPES = [\n",
    "    \"Crane\", \"Excavator\", \"ConcreteMixer\", \"Generator\", \"Forklift\", \"Bulldozer\", \"DumpTruck\", \n",
    "    \"BoomLift\", \"ScissorLift\", \"WeldingMachine\", \"AirCompressor\", \"HydraulicPress\", \"TowerCrane\",\n",
    "    \"RoadRoller\", \"PileDriver\", \"CrawlerLoader\", \"Graders\", \"Trenchers\", \"Pumps\", \"Drills\",\n",
    "    \"MobileScaffolding\", \"DirectionalDrill\", \"ConcretePump\", \"PowerSaw\", \"JackHammer\",\n",
    "    \"LaserLevel\", \"GroundPenetradar\", \"DronesSurvey\", \"CablePuller\", \"PortableLifts\"\n",
    "]\n",
    "\n",
    "# 30 material types\n",
    "MATERIAL_TYPES = [\n",
    "    \"Concrete\", \"SteelBeam\", \"Rebar\", \"ElectricCable\", \"Ducting\", \"FiberOptics\", \"NetworkingRack\",\n",
    "    \"HVACDuct\", \"InsulationPanels\", \"GlassPanels\", \"Bricks\", \"Asphalt\", \"Sand\", \"Gravel\", \"Lumber\",\n",
    "    \"RoofingSheets\", \"PlasticPipes\", \"CopperTubing\", \"WiringHarness\", \"ServerChassis\", \n",
    "    \"CoolingPipes\", \"RaisedFloorPanels\", \"FireProofing\", \"EpoxyCoat\", \"SecuritySensors\",\n",
    "    \"DoorFrames\", \"MetalDoors\", \"AccessPanels\", \"FiberPatchCords\", \"DataCabinets\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef910ae-d15e-4a44-8505-8223f3f90ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 We'll store final data in lists\n",
    "mega_projects = []\n",
    "workstreams = []\n",
    "people = []\n",
    "equipment_list = []\n",
    "material_list = []\n",
    "suppliers = []\n",
    "teams = []\n",
    "tasks = []\n",
    "procurement_orders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa47e98a-a3d7-4e6a-93ea-1f0908f9bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Generate Projects\n",
    "for i in range(NUM_PROJECTS):\n",
    "    start_dt = fake.date_time_between(start_date='-2y', end_date='-1y')\n",
    "    plan_end_dt = start_dt + timedelta(days=random.randint(300, 800))  # large range\n",
    "    pr = {\n",
    "        \"id\": f\"proj_{i}\",\n",
    "        \"projectID\": f\"PROJECT-{1000+i}\",\n",
    "        \"projectName\": f\"MegaDataCenter_{i}\",\n",
    "        \"overallBudget\": round(random.uniform(10_000_000, 500_000_000), 2),\n",
    "        \"startDate\": start_dt.isoformat(),\n",
    "        \"plannedEndDate\": plan_end_dt.isoformat(),\n",
    "        \"actualEndDate\": None  # we might set if \"completed\"\n",
    "    }\n",
    "    mega_projects.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64725eaf-720a-4449-8b94-b6a61b15e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Generate WorkStreams\n",
    "ws_id = 0\n",
    "for proj in mega_projects:\n",
    "    # random # of workstreams (50-150)\n",
    "    num_ws = random.randint(WORKSTREAMS_MIN, WORKSTREAMS_MAX)\n",
    "    proj_start = datetime.fromisoformat(proj[\"startDate\"])\n",
    "    proj_end = datetime.fromisoformat(proj[\"plannedEndDate\"])\n",
    "    for _ in range(num_ws):\n",
    "        ws_start_offset = random.randint(0, max(0,(proj_end - proj_start).days // 2))\n",
    "        ws_start = proj_start + timedelta(days=ws_start_offset)\n",
    "        ws_end = ws_start + timedelta(days=random.randint(60,200))\n",
    "        if ws_end > proj_end:\n",
    "            ws_end = proj_end  # clamp\n",
    "\n",
    "        ws_budget = round(random.uniform(500_000, 5_000_000), 2)\n",
    "        w = {\n",
    "            \"id\": f\"ws_{ws_id}\",\n",
    "            \"workStreamID\": f\"WS-{5000 + ws_id}\",\n",
    "            \"name\": f\"Workstream_{ws_id}_{fake.word().title()}\",\n",
    "            \"description\": fake.sentence(nb_words=8),\n",
    "            \"startDate\": ws_start.isoformat(),\n",
    "            \"endDate\": ws_end.isoformat(),\n",
    "            \"budgetAllocated\": ws_budget,\n",
    "            \"projectID\": proj[\"id\"]\n",
    "        }\n",
    "        workstreams.append(w)\n",
    "        ws_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e605b06c-1bbe-4bc7-834c-0eb641c28d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Generate People\n",
    "for i in range(NUM_PEOPLE):\n",
    "    skill = random.choice(LABOR_SKILLS)\n",
    "    hr_rate = round(random.uniform(10, 100), 2)\n",
    "    p = {\n",
    "        \"id\": f\"person_{i}\",\n",
    "        \"personID\": f\"EMP-{8000 + i}\",\n",
    "        \"name\": fake.name(),\n",
    "        \"skillType\": skill,\n",
    "        \"hourlyRate\": hr_rate,\n",
    "        # resourceType=\"Labor\" in an actual combined structure\n",
    "    }\n",
    "    people.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f968890-c60a-4c10-af8a-7d2d009c612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Generate Equipment (some multiple of 30 types)\n",
    "EQUIP_TOTAL = 100  # or more\n",
    "for i in range(EQUIP_TOTAL):\n",
    "    eq_type = random.choice(EQUIPMENT_TYPES)\n",
    "    daily_cost = round(random.uniform(100, 2000), 2)\n",
    "    eq = {\n",
    "        \"id\": f\"equip_{i}\",\n",
    "        \"equipmentID\": f\"EQ-{1000 + i}\",\n",
    "        \"equipmentName\": f\"{eq_type}_{i}\",\n",
    "        \"equipmentType\": eq_type,\n",
    "        \"dailyRentalCost\": daily_cost,\n",
    "        \"capacityOrSpecs\": f\"{eq_type} spec details\",\n",
    "        # resourceType=\"Equipment\"\n",
    "    }\n",
    "    equipment_list.append(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88d0356-9f98-43c2-972d-fa0f6872144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Generate Materials\n",
    "MAT_TOTAL = 100\n",
    "for i in range(MAT_TOTAL):\n",
    "    mtype = random.choice(MATERIAL_TYPES)\n",
    "    cost_unit = round(random.uniform(1, 500), 2)\n",
    "    # We'll link to a random supplier later or store a placeholder\n",
    "    mat = {\n",
    "        \"id\": f\"mat_{i}\",\n",
    "        \"materialID\": f\"MAT-{1000 + i}\",\n",
    "        \"materialName\": f\"{mtype}_{i}\",\n",
    "        \"materialType\": mtype,\n",
    "        \"unitCost\": cost_unit,\n",
    "        \"quantityOnHand\": random.randint(500, 100000),\n",
    "        # resourceType=\"Material\"\n",
    "    }\n",
    "    material_list.append(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee896a69-55f8-4c4a-b340-84556d48f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Generate Suppliers (80)\n",
    "for i in range(NUM_SUPPLIERS):\n",
    "    sup = {\n",
    "        \"id\": f\"sup_{i}\",\n",
    "        \"supplierID\": f\"SUP-{1000 + i}\",\n",
    "        \"supplierName\": fake.company() + \" Supplies\",\n",
    "        \"location\": fake.city()\n",
    "    }\n",
    "    suppliers.append(sup)\n",
    "\n",
    "# We'll link some suppliers to some materials/equipment\n",
    "for mat in material_list:\n",
    "    # 70% chance to have a supplier\n",
    "    if random.random() < 0.7:\n",
    "        s = random.choice(suppliers)\n",
    "        mat[\"supplierID\"] = s[\"id\"]\n",
    "for eq in equipment_list:\n",
    "    # 40% chance to have a supplier\n",
    "    if random.random() < 0.4:\n",
    "        s = random.choice(suppliers)\n",
    "        eq[\"supplierID\"] = s[\"id\"]  # we'll store it for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "849d53e3-0ac4-489a-aa22-7176ca0b4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Generate Teams\n",
    "for i in range(NUM_TEAMS):\n",
    "    t = {\n",
    "        \"id\": f\"team_{i}\",\n",
    "        \"teamID\": f\"TM-{3000 + i}\",\n",
    "        \"teamName\": f\"Team_{i}_{fake.word().title()}\",\n",
    "        # we might link persons but let's store them as a separate step\n",
    "    }\n",
    "    # optional: link random subset of persons\n",
    "    # We'll store references in a separate data structure or a key \"personIDs\"\n",
    "    t[\"personIDs\"] = []\n",
    "    # pick 5-20 random people\n",
    "    n_members = random.randint(5, 20)\n",
    "    chosen_people = random.sample(people, k=n_members)\n",
    "    t[\"personIDs\"] = [cp[\"id\"] for cp in chosen_people]\n",
    "\n",
    "    teams.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49113260-ab48-4417-9e28-a7d99389e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Generate ProcurementOrders referencing suppliers & resources\n",
    "# We'll do a smaller number of POs because tasks are huge\n",
    "NUM_PROC_ORDERS = 2000\n",
    "for i in range(NUM_PROC_ORDERS):\n",
    "    # random supplier\n",
    "    sp = random.choice(suppliers)\n",
    "    # pick random resource(s) from either equip or material\n",
    "    res_count = random.randint(1,3)\n",
    "    res_type_choice = random.choice([\"equip\",\"mat\"])\n",
    "    resources_chosen = []\n",
    "    if res_type_choice == \"equip\":\n",
    "        resources_chosen = random.sample(equipment_list, k=res_count)\n",
    "    else:\n",
    "        resources_chosen = random.sample(material_list, k=res_count)\n",
    "\n",
    "    # random project link\n",
    "    proj = random.choice(mega_projects)\n",
    "    order_d = fake.date_time_between_dates(datetime_start=datetime.fromisoformat(proj[\"startDate\"]),\n",
    "                                           datetime_end=datetime.now())\n",
    "\n",
    "    total_c = round(sum([r[\"unitCost\"] if \"unitCost\" in r else r[\"dailyRentalCost\"] for r in resources_chosen])*random.uniform(5,100),2)\n",
    "    po = {\n",
    "        \"id\": f\"po_{i}\",\n",
    "        \"orderNumber\": f\"PO-{10000+i}\",\n",
    "        \"orderDate\": order_d.isoformat(),\n",
    "        \"totalCost\": total_c,\n",
    "        \"supplierID\": sp[\"id\"],\n",
    "        \"resourceIDs\": [r[\"id\"] for r in resources_chosen],\n",
    "        \"belongsToProjectID\": proj[\"id\"]\n",
    "    }\n",
    "    procurement_orders.append(po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9553b0-9b25-4e92-9383-a23313405d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Generate Tasks (including CommissioningActivity for ~5%) \n",
    "# We have 3000 tasks per project => 300k tasks total. This is huge in memory.\n",
    "tasks = []\n",
    "task_id_counter = 0\n",
    "\n",
    "for proj in mega_projects:\n",
    "    # gather that project's workstreams\n",
    "    p_ws = [ws for ws in workstreams if ws[\"projectID\"] == proj[\"id\"]]\n",
    "    if not p_ws:\n",
    "        # at least one in theory, but just skip if none\n",
    "        continue\n",
    "\n",
    "    for t_count in range(TASKS_PER_PROJECT):\n",
    "        # random: pick a normal Task or a CommissioningActivity (5% chance)\n",
    "        is_commission = (random.random() < COMMISSIONING_PCT)\n",
    "\n",
    "        # pick random ws\n",
    "        sel_ws = random.choice(p_ws)\n",
    "        ws_start_dt = datetime.fromisoformat(sel_ws[\"startDate\"])\n",
    "        ws_end_dt = datetime.fromisoformat(sel_ws[\"endDate\"])\n",
    "\n",
    "        # generate a start offset\n",
    "        total_ws_days = (ws_end_dt - ws_start_dt).days\n",
    "        if total_ws_days < 10:\n",
    "            total_ws_days = 10\n",
    "\n",
    "        # if we want 30% overlap, we won't necessarily do perfect offset checks,\n",
    "        # just random: 30% chance we forcibly pick a start that is within an overlapping window\n",
    "        if random.random() < OVERLAP_PCT:\n",
    "            # pick a random start in the first half\n",
    "            start_offset = random.randint(0, total_ws_days // 2)\n",
    "        else:\n",
    "            # normal approach\n",
    "            start_offset = random.randint(0, total_ws_days - 1)\n",
    "\n",
    "        t_start = ws_start_dt + timedelta(days=start_offset)\n",
    "        # random duration\n",
    "        dur = random.randint(5,50)\n",
    "        t_end = t_start + timedelta(days=dur)\n",
    "        if t_end > ws_end_dt:\n",
    "            t_end = ws_end_dt\n",
    "\n",
    "        cost_est = round(random.uniform(50_000,1_000_000),2)\n",
    "        mil_flag = (random.random() < 0.03)  # 3% tasks are milestone\n",
    "\n",
    "        # Build the base Task dictionary\n",
    "        base_task = {\n",
    "            \"id\": f\"task_{task_id_counter}\",\n",
    "            \"taskID\": f\"TK-{10000+task_id_counter}\",\n",
    "            \"taskName\": f\"Task_{task_id_counter}_{fake.bs().title()}\",\n",
    "            \"startDate\": t_start.isoformat(),\n",
    "            \"endDate\": t_end.isoformat(),\n",
    "            \"durationDays\": (t_end - t_start).days,\n",
    "            \"costEstimate\": cost_est,\n",
    "            \"actualCost\": 0.0,\n",
    "            \"isCritical\": False,\n",
    "            \"milestoneFlag\": mil_flag,\n",
    "            \"workStreamID\": sel_ws[\"id\"],\n",
    "            \"dependsOnIDs\": [],\n",
    "            \"laborIDs\": [],\n",
    "            \"equipmentIDs\": [],\n",
    "            \"materialIDs\": [],\n",
    "            \"teamID\": None\n",
    "        }\n",
    "\n",
    "        if is_commission:\n",
    "            # It's a specialized CommissioningActivity\n",
    "            # We'll store extra fields\n",
    "            base_task[\"classType\"] = \"CommissioningActivity\"  # marker\n",
    "            base_task[\"commissioningChecklist\"] = \"Checklist items...\"\n",
    "            base_task[\"passDate\"] = None  # we can fill in if needed\n",
    "        else:\n",
    "            base_task[\"classType\"] = \"Task\"\n",
    "\n",
    "        tasks.append(base_task)\n",
    "        task_id_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d212aa6-d100-43d3-8bdc-da069ce0f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 Build dependencies for tasks within the same project\n",
    "# We'll do a two-pass approach:\n",
    "#  - Sort tasks by startDate per project, then assign up to 3 dependencies from earlier tasks\n",
    "# TODO: PARALLELIZE THIS CODE, THIS NAIVE APPROACH TAKES WAAAAAYYYY TOO MUCH TIME...\n",
    "tasks_by_project = defaultdict(list)\n",
    "for t in tasks:\n",
    "    # we can find project by looking up the workstream -> project\n",
    "    wsid = t[\"workStreamID\"]\n",
    "    wsobj = next((w for w in workstreams if w[\"id\"] == wsid), None)\n",
    "    if wsobj:\n",
    "        p_id = wsobj[\"projectID\"]\n",
    "        tasks_by_project[p_id].append(t)\n",
    "\n",
    "for p_id, tlist in tasks_by_project.items():\n",
    "    tlist.sort(key=lambda x: x[\"startDate\"])\n",
    "    for idx, tsk in enumerate(tlist):\n",
    "        start_t = datetime.fromisoformat(tsk[\"startDate\"])\n",
    "        # gather earlier tasks that end before this start\n",
    "        possible_deps = []\n",
    "        for j in range(idx):\n",
    "            cand = tlist[j]\n",
    "            cand_end = datetime.fromisoformat(cand[\"endDate\"])\n",
    "            if cand_end <= start_t:\n",
    "                possible_deps.append(cand[\"id\"])\n",
    "        # pick up to 3\n",
    "        nd = random.randint(0, min(3, len(possible_deps)))\n",
    "        if nd>0:\n",
    "            chosen = random.sample(possible_deps, nd)\n",
    "            tsk[\"dependsOnIDs\"] = chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72581636-8562-4f54-b9a4-45ea7a2a80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 Resource assignment to tasks\n",
    "# We'll do random: 1-10 labor, 0-2 equipment, 0-4 materials, 0-1 team\n",
    "for tsk in tasks:\n",
    "    # labor\n",
    "    n_labor = random.randint(1,10)\n",
    "    chosen_people = random.sample(people, n_labor)\n",
    "    tsk[\"laborIDs\"] = [cp[\"id\"] for cp in chosen_people]\n",
    "\n",
    "    # equip\n",
    "    eq_count = random.randint(0,2)\n",
    "    eq_chosen = random.sample(equipment_list, eq_count)\n",
    "    tsk[\"equipmentIDs\"] = [e[\"id\"] for e in eq_chosen]\n",
    "\n",
    "    # material\n",
    "    mat_count = random.randint(0,4)\n",
    "    mat_chosen = random.sample(material_list, mat_count)\n",
    "    tsk[\"materialIDs\"] = [m[\"id\"] for m in mat_chosen]\n",
    "\n",
    "    # maybe assign a team\n",
    "    if random.random()<0.2:\n",
    "        t = random.choice(teams)\n",
    "        tsk[\"teamID\"] = t[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4963fff4-b3a9-41b2-a016-672cc587f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 Approximate \"critical path\" marking\n",
    "# We'll do a naive \"longest path\" approach per project\n",
    "dist_cache = {}\n",
    "children_map = defaultdict(list)\n",
    "task_map = {}\n",
    "for t in tasks:\n",
    "    task_map[t[\"id\"]] = t\n",
    "\n",
    "for t in tasks:\n",
    "    for dID in t[\"dependsOnIDs\"]:\n",
    "        children_map[dID].append(t[\"id\"])\n",
    "\n",
    "def dfs_longest(tid):\n",
    "    if tid in dist_cache:\n",
    "        return dist_cache[tid]\n",
    "    ch = children_map[tid]\n",
    "    if not ch:\n",
    "        dist_cache[tid] = (0,[tid])\n",
    "        return (0,[tid])\n",
    "    maxd = -1\n",
    "    best_path=[]\n",
    "    for c in ch:\n",
    "        d,chain = dfs_longest(c)\n",
    "        if d>maxd:\n",
    "            maxd = d\n",
    "            best_path=chain\n",
    "    dist_cache[tid] = (1+maxd, [tid]+best_path)\n",
    "    return dist_cache[tid]\n",
    "\n",
    "# We'll do it per project\n",
    "for p_id, tlist in tasks_by_project.items():\n",
    "    # find roots: tasks with no dependsOn\n",
    "    roots = [x for x in tlist if not x[\"dependsOnIDs\"]]\n",
    "    for r in roots:\n",
    "        dfs_longest(r[\"id\"])\n",
    "    # find global max for that project\n",
    "    local_max=-1\n",
    "    local_chain=[]\n",
    "    for t in tlist:\n",
    "        tid = t[\"id\"]\n",
    "        if tid in dist_cache:\n",
    "            (dist,chain)=dist_cache[tid]\n",
    "            if dist>local_max:\n",
    "                local_max=dist\n",
    "                local_chain=chain\n",
    "    # Mark tasks in local_chain as isCritical\n",
    "    for ctid in local_chain:\n",
    "        task_map[ctid][\"isCritical\"]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdbdb6a9-8b80-4977-99cd-5820042388b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Generation Complete ---\n",
      "Created Data Summary:\n",
      "\n",
      " MegaProjects: 100\n",
      " WorkStreams: 9734\n",
      " People(Labor): 2000\n",
      " EquipmentResources: 100\n",
      " MaterialResources: 100\n",
      " Suppliers: 80\n",
      " Teams: 500\n",
      " ProcurementOrders: 2000\n",
      " Tasks: 300000  (approx. 3000 per project => ~300k total)\n"
     ]
    }
   ],
   "source": [
    "# Summaries\n",
    "print(\"\\n--- Data Generation Complete ---\")\n",
    "print(\"Created Data Summary:\\n\")\n",
    "print(\" MegaProjects:\", len(mega_projects))\n",
    "print(\" WorkStreams:\", len(workstreams))\n",
    "print(\" People(Labor):\", len(people))\n",
    "print(\" EquipmentResources:\", len(equipment_list))\n",
    "print(\" MaterialResources:\", len(material_list))\n",
    "print(\" Suppliers:\", len(suppliers))\n",
    "print(\" Teams:\", len(teams))\n",
    "print(\" ProcurementOrders:\", len(procurement_orders))\n",
    "print(\" Tasks:\", len(tasks), \" (approx. 3000 per project => ~300k total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9389483f-77c6-45f6-a1e8-23b223b8f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample MegaProject:\n",
      " {'id': 'proj_0', 'projectID': 'PROJECT-1000', 'projectName': 'MegaDataCenter_0', 'overallBudget': 460459136.18, 'startDate': '2023-11-14T06:25:17', 'plannedEndDate': '2025-08-30T06:25:17', 'actualEndDate': None}\n",
      "\n",
      "Sample WorkStream:\n",
      " {'id': 'ws_0', 'workStreamID': 'WS-5000', 'name': 'Workstream_0_Song', 'description': 'Degree compare much tough pick effect political.', 'startDate': '2024-08-20T06:25:17', 'endDate': '2024-10-26T06:25:17', 'budgetAllocated': 639931.73, 'projectID': 'proj_0'}\n",
      "\n",
      "Sample Person (Labor):\n",
      " {'id': 'person_0', 'personID': 'EMP-8000', 'name': 'Robin Anderson', 'skillType': 'CraneOperator', 'hourlyRate': 92.18}\n",
      "\n",
      "Sample Equipment:\n",
      " {'id': 'equip_0', 'equipmentID': 'EQ-1000', 'equipmentName': 'AirCompressor_0', 'equipmentType': 'AirCompressor', 'dailyRentalCost': 350.36, 'capacityOrSpecs': 'AirCompressor spec details', 'supplierID': 'sup_13'}\n",
      "\n",
      "Sample Material:\n",
      " {'id': 'mat_0', 'materialID': 'MAT-1000', 'materialName': 'AccessPanels_0', 'materialType': 'AccessPanels', 'unitCost': 21.06, 'quantityOnHand': 53668}\n",
      "\n",
      "Sample Supplier:\n",
      " {'id': 'sup_0', 'supplierID': 'SUP-1000', 'supplierName': 'Dominguez, Allen and Williams Supplies', 'location': 'North Anthony'}\n",
      "\n",
      "Sample Team:\n",
      " {'id': 'team_0', 'teamID': 'TM-3000', 'teamName': 'Team_0_Than', 'personIDs': ['person_1859', 'person_530', 'person_578', 'person_1752', 'person_1918', 'person_1792', 'person_1026', 'person_1296']}\n",
      "\n",
      "Sample ProcurementOrder:\n",
      " {'id': 'po_0', 'orderNumber': 'PO-10000', 'orderDate': '2024-12-16T00:21:45', 'totalCost': 20926.52, 'supplierID': 'sup_66', 'resourceIDs': ['mat_22'], 'belongsToProjectID': 'proj_23'}\n",
      "\n",
      "Sample Task:\n",
      " {'id': 'task_0', 'taskID': 'TK-10000', 'taskName': 'Task_0_Incentivize B2B Interfaces', 'startDate': '2024-08-23T06:25:17', 'endDate': '2024-09-19T06:25:17', 'durationDays': 27, 'costEstimate': 257265.06, 'actualCost': 0.0, 'isCritical': False, 'milestoneFlag': False, 'workStreamID': 'ws_24', 'dependsOnIDs': [], 'laborIDs': ['person_506', 'person_1959', 'person_568'], 'equipmentIDs': ['equip_33', 'equip_52'], 'materialIDs': ['mat_82'], 'teamID': None, 'classType': 'Task'}\n"
     ]
    }
   ],
   "source": [
    "# print sample\n",
    "print(\"\\nSample MegaProject:\\n\", mega_projects[0])\n",
    "print(\"\\nSample WorkStream:\\n\", workstreams[0])\n",
    "print(\"\\nSample Person (Labor):\\n\", people[0])\n",
    "print(\"\\nSample Equipment:\\n\", equipment_list[0])\n",
    "print(\"\\nSample Material:\\n\", material_list[0])\n",
    "print(\"\\nSample Supplier:\\n\", suppliers[0])\n",
    "print(\"\\nSample Team:\\n\", teams[0])\n",
    "print(\"\\nSample ProcurementOrder:\\n\", procurement_orders[0])\n",
    "print(\"\\nSample Task:\\n\", tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "201047b5-0d0b-483f-a9fa-059f7ab9b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the data\n",
    "pd.DataFrame(mega_projects).to_csv(data_path+\"mega_projects.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(workstreams).to_csv(data_path+\"workstreams.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(people).to_csv(data_path+\"people.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(equipment_list).to_csv(data_path+\"equipment_list.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(material_list).to_csv(data_path+\"material_list.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(suppliers).to_csv(data_path+\"suppliers.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(teams).to_csv(data_path+\"teams.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(procurement_orders).to_csv(data_path+\"procurement_orders.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)\n",
    "pd.DataFrame(tasks).to_csv(data_path+\"tasks.csv\", encoding = \"utf-8\", escapechar = \"\\\"\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3e6b4-c9a7-4e8a-98ac-c9a55759b2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b340af-f830-4e8b-8743-8fcf08164eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
